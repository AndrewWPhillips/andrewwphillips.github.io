---
title: "Go 1.25 Is Here!"
last_modified_at: 2025-08-16T16:34:00+10:00
excerpt: Go 1.25 has a couple of nice additions and a few that are overhyped
toc: true
toc_sticky: true
categories: [language,releases]
tags: [release,synctest]
header:
  overlay_image: "/assets/images/floatingeggs.jpg"
  overlay_filter: 0.4
permalink: /blog/go1p25.html
---

# Go 1.25

These are the most significant additions in Go 1.25 IMHO:

* [synctest](#synctest) which I discussed [last time](https://andrewwphillips.github.io/blog/go1p24.html#new-synctest-package). I also did a [talk](https://www.youtube.com/watch?v=KAImJOqagXY)
* a [new Garbage Collector](#green-tea-gc) which is more cache friendly
* Number of goroutines is better/dynamically adjusted - see [GOMAXPROCS](#gomaxprocs)
* [WaitGroup](#waitgroup) adds a nicety (with a gotcha)
* [JSON v2 package](#json-v2) decodes faster, and adds interesting surprises
* [Trace Flight Recorder](#trace-flight-recorder) is a really cool addition that allows continuous trace recording (into a ring buffer) allowing you to dump a trace of the last few seconds of execution when something __interesting__ happens

After trying these things in depth I found some useful: synctest (of course), trace flight recorder, and the new JSON v2 `unknown` tag.

Some other things sound good on paper, but may have been overhyped by some bloggers: new WaitGroup `Go()` method, `GOMAXPROCS` tweaks, etc, as discussed below.  **Please correct me if I am wrong about any of these**.

## Background

<!--****************************-->
<details markdown="1">
<summary>Garbage Collector</summary>
<br/>


---
</details>

<!--****************************-->
<details markdown="1">
<summary>GOMAXPROCS</summary>
<br/>

- previously: unmarshall into struct OR []any AND map[string]any

---
</details>
<!--****************************-->
<br/>

## GOMAXPROCS

If you don't understand what `GOMAXPROCS` is for and how/when/why the Go runtime creates/deletes/reuses threads (to run its goroutines) I explain it in detail in the **Background/Go** section above, but the salient points are:

1. GOMAXPROCS = number of threads used for goroutines
2. It defaults to an estimate of _available_ CPUs
3. It can be set dynamically using `runtime.GOMAXPROCS()`
4. It can bet set back to the default using `runtime.defaultGOMAXPROCS()`

It's the 2nd point that is sometimes a problem because the way that the runtime detects the number of available CPUs is simplistic.  Moreover, it's set from the GOMAXPROCS environment variable at startup, and never modified, though it is becoming more common for the number of available CPUs to change dynamically.

### The Uses of GOMAXPROCS

The Go runtime tries to keep the CPUs busy by using, at any time, GOMAXPROCS threads for running it's (non-blocked) goroutines. The exact effect of GOMAXPROCS on your software depends a lot on your code and even the OS (operating system) and the Go runtime version.

If you never create any goroutines - never use the `go` keyword, and don't use any packages that do so - then all your code runs in a single goroutine - in this case GOMAXPROCS has no effect on the performance.  (Though extra goroutine(s) may be used for garbage collections.)  However, if you create lots of goroutines it can be important, though (unless your code is CPU bound) I have found that it does not noticeably affect performance.

My experience is with server software running on hardware with 20 or more cores.  I run a certain piece of Go software on 4 servers across the world and at times has 3 million or more goroutines.  It typically only uses 5% CPU (with occasional spikes up to 30%).  I have done lots of testing, as I can easily (dynamically) control the value.

The general wisdom is GOMAXPROCS should be no more than the numbers of (hardware) cores, but I have found low value has no effect on throughput, though there is an effect on latency for very low values.  It has even been reported that setting GOMAXPROCS higher than recommended can actually improve performance (though this may be for older version of Go and/or depend on the OS, etc).

### Available CPUs?

The number of available CPUs could be affected by many things, like other processes running on the same system (perhaps at a higher priority) which hog the CPU(s).  In this case, we are talking about the number of cores made available by the OS for a process to use; for a Go program this is the number of (non-blocked) threads available to run goroutines.

For example, on a laptop with a low battery, the OS may decide to shut down some CPUs to save power.

In Linux processes can be configured to have fewer CPUs available using the `cgroups` facility.  This is used for the `--cpus` docker option, when running containers under Linux.

### Improvements in Go 1.25

The changes in Go 1.25 address two related issues:

1. The number of available CPUs may be less than the number of hardware cores that the Go runtime detects
2. The number of available CPUs can change dynamically

In Go 1.25 the runtime will regularly checks more cleverly for how many CPUs are available and adjust the number of threads it uses for go-routines dynamically.

For example, cgroups in Linux which can be used to reduce how may cores are available to a process.  An extreme example might be running a docker container using the `--cpus 2` command line flag on a server with 256 cores.  A Go program running in the container would default to a large value for GOMAXPROCS but in Go 1.25 the Go runtime will detect that there are only 2 available CPUs (not 256).

Personally, this will not affect me as I already dynamically control this using `runtime.GOMAXPROCS()`.  I know that a lot of software does this - for example using the [automaxprocs](https://github.com/uber-go/automaxprocs) open-source package.  And for a lot of software it will have no appreciable effect.

If you set the `GOMAXPROCS` environment variable, or call `runtime.GOMAXPROCS()` (with a +ve value), then the Go runtime will assume you know what you are doing and not dynamically adjust its goroutines (unless you subsequently call `runtime.defaultGOMAXPROCS()`).
{: .notice--warning}

## Green Tea GC

There's probably nothing that stirs up more controversy around Go than its garbage collector.  In the [Background](#background) section above I discuss the controversy, and my own struggles with (what I thought was) latency due to background goroutines used for GC.

Even earlier, my initial reticence for Go was due to bad experiences with GC (3rd gen.) collections in Java and C# -- so I was extremely wary of a GC language esp. for backend (server) software.  But the simple fact is the Go garbage collector make life easy without a (major) impact on performance.

### Brief GC History

Over many years and culminating in Go 1.10 (from memory) the garbage collector was improved incredibly until STW (stop the world) pauses were reduced to sub-millisecond times.  The main work of the GC takes a lot longer (typicalle a fw seconds every few minutes), but this can process concurrently with the work in other goroutines.

- GC proceeds concurretly

- pre-emption
- 
There was still a problem though since scheduling of goroutines was somewhat cooperative.  That is, a badly behaved goroutine could hog a thread indefinitely.  This mya not be a problem, if you have many cores, but if there was just one goroutine doing this then everything stopped

### Who does it affect?

Unlike the `GOMAXPROCS` improvement mentioned above, this will (IMHO) affect the performance of a lot more Go code.

A lot of software in Go is GC-intense.  Escape-analysis is good (but could be improved) and the obvious way to write code often leads to more allocations than necessary (though Go is nowhere near as bad as Java in this respect).

Running traces to compare the old and new GCs, I found that garbage collections use less goroutines.  This means there are more goroutines available to run your code.

### It's all about the Cache

Ever since the internal CPU clock speed of microprocessors started deviating from the bus (memory) clock speed (close to 50 years ago now) the importance of how your code works with the cache has become more and more important.

In GC-intensive Go code a garbage collection will likely involve several goroutines xxxing

- multiple goroutines for

## Trace Flight Recorder

The execution tracer is an incredible tool (unique to Go) that allows you to examine what your goroutines, the garbage collector, and the Go runtime are doing in exquisite detail.

The Trace Flight Recorder is a further refinement that allows you to continually generate trace data (into a circular buffer).  Then, at any time, you can trigger a dump of the last few seconds of trace data.  This is very useful when you want to analyse an event that is triggered rarely for an unknown reason.

### Understanding code behaviour

Go has a lot of tools out of the box that allow you to create great code.  However, because there are so many facilities, the execution tracer tends to be forgotten.  Eg.:

* automated tests - to make sure you code is correct + help find/fix bugs
* benchmarks - to make sure your code is fast + help find/fix performance problems
* CPU profile - understand where CPU time is spent
* heap profile - understand how memory (heap) is utilised
* block profile - understand how your goroutines communicate
* other profiles - goroutine, mutex, etc
* GODEBUG (env. var.) - allows logging of things like GCs
* execution tracer - records exact behaviour of you goroutines and their interactions and use of the garbage collector, etc

I discussed these in my blog about Flame Graphs in (Background -> Go)[https://andrewwphillips.github.io/blog/flame-graphs.html#background]

### Execution Tracer

What is the difference between profiling and tracing?  A crucial difference is that profiling uses sampling, while the execution tracer records everything.

Of course, recording all this trace detail is not a simple thing to do (efficiently), and up until early last year the execution tracer had some problems - as I mentioned in my blog on Go 1.22 [Execution Tracer](/blog/go1p22.html#execution-tracer)

Since Go 1.22 the execution tracer works brilliantly!  So much so that I often turn it on in production in order to understand some problem.  The overhead of recording a trace is small (even negligible), except that if you record for a long time it will use a lot of memory.

### Why Do I Need It?

In a career of 45+ years (mainly C and C++) I have encountered lots of mysterious runtime issues (crashes, slowness, etc).  Luckily, Go makes it orders of magnitude easier to create reliable software, but sometimes there are still things that are difficult to understand.

In Go, these are usually performance problems often related to the garbage collector.  When I had these problems in the past I found it a trace was invaluable.  For example in my (server) software I can generate a 5-second trace at any time.

The problem is that vital evidence may have disappeared by the time the trace is generated.

### Using the Flight Recorder

This is where the Trace Flight Recorder comes in handy.  Now I can have tracing on all the time, and it will keep recording into a circular buffer.

```go
    recorder := trace.NewFlightRecorder(trace.FlightRecorderConfig{MaxBytes: 10e6})
    if err := recorder.Start(); err != nil {
        // return or handle error
    }
    defer recorder.Stop() // optional
```

This will use no more than 10Mbytes of memory.  Note that you can also restrict the trace length to a number of seconds, but I find it simpler to just specify how much memory I want to reserve for the circular buffer.

Now, if you detect a problem, you can immediately trigger a dump of the trace for the last few seconds:

```go
    if traceWantedForSomeReason() {
        file, err := os.Create("trace_" + time.Now().UTC().Format("060102150405") + ".out")
		if err != nil {
			t.Fatal("Could not create trace file:", err.Error())
		}
		_, err = ptfr.WriteTo(file)
		if err != nil {
			t.Fatal("Could not write trace file:", err.Error())
		}
		file.Close()
    }
```

### Examining Traces

Finally, I should mention that one of the coolest things about execution traces is the tooling provided to inspect them.  The easiest way is to just run this command:

$ go tool trace trace.out

A web page is generated that allows you to inspect the trace in various ways.  I will talk about this in detail in a future post.

## JSON v2

- 2 pkg: json and jsontext

- unknown tag
**JSON v2**

Unlike a lot of people I have not had many problems with the standard library JSON package.  However, I do like many things in the new **v2** JSON package, such as improved decoding performance.  And the new `unknown` tag is particularly useful.

- reject duplicate names

## WaitGroup

Waitgroups are a mainstay of working with goroutines, but it is easy to make mistakes.

### WaitGroup Gotchas

With complex uses of `WaitGroup` it can be tricky to ensure that your use of `Add()` balances your calls to `Done()`.  Luckily, if you call `Done()` too many times your code will panic with the message **panic: sync: negative WaitGroup counter**.

Unluckily, if you call `Done()` **too few** times then you can get deadlocks, goroutine leaks or just pain mysterious issues.  One way to address this would be to have a variation of Waitgroup with a context in order to timeout -- this has **not** been added to the standard library, but maybe one day.

Another common mistake is **not calling `Add()` in the correct place**.  For example:

```go
    var wg sync.WaitGroup
    go func() {
        wg.Add(1)
		// Something that we await to finish
        wg.Done()
    }()
    wg.Wait()
```
This code can work if the new goroutine starts immediately and `wg.Add(1)` executes before `wg.Wait()`.  But more likely the `Wait()` will execute first and, since the wait group count is still zero, `Done()` returns immediately.

### Errgroup

This (and other) problem(s) with `sync.Waitgroup` were addressed by the Go developers in 2016.  The above problem is fixed simply like this:

```go
import "golang.org/x/sync/errgroup"
...
    var eg errgroup.Group
    eg.Go(func() error {
        // Something that we await to finish
    })

```

### New `Go()` Method

Go 1.25 finally adds errgroup's `Go()` function to the standard library.  I always preferred `errgroup`, but now maybe I'll switch back again.

**Gotcha** One problem with using the new `Go()` method is that it's not obvious that it runs your code in a new goroutine.  For example, if you are "catching" panics (using `recover()`) in the outer goroutine they will not be caught in the function passed to the `Go()` method.  If you want to avoid panics terminating the whole program you also need to add a call to `recover()` inside a deferred function with the passed function. 
{: .notice--warning}

## synctest

Finally, a quick update on the new `synctest` package (available as an "experiment" in Go 1.24).  I talked about if effusively [last time](https://andrewwphillips.github.io/blog/go1p24.html#new-synctest-package).

### synctest.Test()

In the Go 1.24 experiment you'd call `synctest.Run(f)`.  This takes one parameter (`f`) - the function to be run inside the bubble.

```go
func TestSyncTest(t *testing.T) {
	synctest.Run(func() { // deprecated in G0 1.25
        // code to run in the bubble
	})
}
```

In Go 1.25, this has been replaced with `synctest.Test(t, f)` which also takes a `*testing.T` parameter.  (This was done for a minor technical issue which I'm not sure I agree with, since it restricts synctest to only be used with tests.)

```go
func TestSyncTest(t *testing.T) {
	synctest.Test(t, func() {
        // code to run in the bubble
	})
}
```

### synctest.Wait()

One comment I got about my synctest examples is that I did not demonstrate the use of `synctest.Wait()`.  Unfortunately, I could not find a good reason to use `synctest.Wait()`.  It is better, at least for external tests, to use the normal Go synchronisation facilities (like `WaitGroup`).

Since then, I have seen some valid uses of synctest.Wait() to verify condtions/state in internal tests, but you should know that I frown on internal tests.

## Conclusion


GOMAXPROCS not esp. useful, but it is a good improvement.

**Trace Flight Recorder**

I also talked effusively about the [Execution Tracer](/blog/go1p22.html#execution-tracer) after it was fixed in Go 1.22.  However, due to the unwieldiness of traces (even though they are much improved from Go 1.22) they often can't be used to catch rarely occurring events in production.

The `runtime/trace.FlightRecorder` allows you to trigger a trace capture of the last few seconds at any time.


**WaitGroup**

Many have fallen afoul of `sync.WaitGroup` though there has been a ready remedy (since 2016) in the form of `golang.org/x/sync/errgroup` but it's great to see the Go 1.25 standard library `sync.WaitGroup` has been fixed.

